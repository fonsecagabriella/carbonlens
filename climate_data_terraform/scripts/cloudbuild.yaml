steps:
# Install dbt
- name: 'python:3.8'
  id: 'install-dbt'
  entrypoint: 'pip'
  args: ['install', 'dbt-bigquery']

# Set up the profiles.yml file
- name: 'python:3.8'
  id: 'setup-profiles'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    mkdir -p /root/.dbt
    cat > /root/.dbt/profiles.yml << EOF
    climate_transforms:
      target: prod
      outputs:
        prod:
          type: bigquery
          method: oauth
          project: ${_PROJECT_ID}
          dataset: ${_BQ_DATASET}
          threads: 4
          timeout_seconds: 300
          location: ${_REGION}
          priority: interactive
          retries: 3
    EOF

# Run dbt
- name: 'python:3.8'
  id: 'run-dbt'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    cd /workspace/dbt_climate_data/climate_transforms
    dbt run --profiles-dir=/root/.dbt

# Test the dbt models
- name: 'python:3.8'
  id: 'test-dbt'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    cd /workspace/dbt_climate_data/climate_transforms
    dbt test --profiles-dir=/root/.dbt

# Generate dbt documentation
- name: 'python:3.8'
  id: 'generate-docs'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    cd /workspace/dbt_climate_data/climate_transforms
    dbt docs generate --profiles-dir=/root/.dbt
    
# Upload dbt docs to GCS
- name: 'gcr.io/cloud-builders/gsutil'
  id: 'upload-docs'
  args: ['cp', '-r', '/workspace/dbt_climate_data/climate_transforms/target', 'gs://${_DBT_BUCKET}/docs/']

# Set substitution variables
substitutions:
  _PROJECT_ID: 'your-project-id'  # Will be replaced by actual value
  _BQ_DATASET: 'climate_warehouse'  # Will be replaced by actual value
  _REGION: 'us-central1'  # Will be replaced by actual value
  _DBT_BUCKET: 'dbt-climate-data'  # Will be replaced by actual value

# Set timeout
timeout: '1800s'